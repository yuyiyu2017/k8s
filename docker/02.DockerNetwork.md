# 一、Linux网络空间与虚拟网卡管理
* 网络名称空间管理
>ip netns help

```
ip netns list
ip netns add NAME
ip netns set NAME NETNSID
ip [-all] netns delete [NAME]
ip netns identify [PID]
ip netns pids NAME
ip [-all] netns exec [NAME] cmd ...
ip netns monitor
ip netns list-id
```

* 虚拟网卡操作
> ip link help

## 1、创建两个网络名称空间
```
ip netns add r1
ip netns add r2
ip netns list
```

## 2、创建一对类型为 veth 的虚拟网卡
>ip link add name veth1.1 type veth peer name veth1.2

## 3、查看网卡绑定状态
>ip link list

```
10: veth1.2@veth1.1: <BROADCAST,MULTICAST,M-DOWN>
11: veth1.1@veth1.2: <BROADCAST,MULTICAST,M-DOWN>
```

## 4、将网卡移动到指定网络名称空间中
>ip link set dev veth1.2 netns r2

## 5、显示指定名称空间中的网卡
>ip netns exec r2 ip link list

```
1: lo: <LOOPBACK>
10: veth1.2@if11: <BROADCAST,MULTICAST>
```

## 6、修改指定名称空间中的网卡名称
>ip netns exec r2 ip link set dev veth1.2 name eth0
>
>ip netns exec r2 ifconfig -a

```
eth0: flags=4098<BROADCAST,MULTICAST>  mtu 1500
lo: flags=8<LOOPBACK>  mtu 65536
```

## 7、激活外层的 veth1.1 网卡，并分配IP
>ifconfig veth1.1 10.1.0.1/24 up
>
>ifconfig

```
veth1.1: flags=4099<UP,BROADCAST,MULTICAST>  mtu 1500
inet 10.1.0.1  netmask 255.255.255.0  broadcast 10.1.0.255
```

## 8、激活内层的 veth1.2 网卡，并分配IP
>ip netns exec r2 ifconfig eth0 10.1.0.2/24 up
>
>ip netns exec r2 ifconfig

```
eth0: flags=4163<UP,BROADCAST,RUNNING,MULTICAST>  mtu 1500
inet 10.1.0.2  netmask 255.255.255.0  broadcast 10.1.0.255
```

## 9、将网卡移动到指定网络名称空间中
>ip link set dev veth1.1 netns r1

## 10、激活内层的 veth1.1 网卡，并分配IP
>ip netns exec r1 ifconfig veth1.1 10.1.0.3/24 up

## 11、测试网络互通性
>ip netns exec r1 ping 10.1.0.2

# 二、docker的网络类型
```
a、bridge网桥
b、host宿主机网络
c、none孤岛模式
d、proxy代理
e、联盟式容器
```

## 1、bridge
>默认网络，Docker启动创建的docker0，创建的容器会添加到这个网桥中

* 创建例举
>docker run -itd nginx
```
"Networks": {
    "bridge": {
        "IPAMConfig": null,
        "Links": null,
        "Aliases": null,
        "NetworkID": "507b9317ac15954247cdcd009237d7dc397b374f0235880c430d7a16aa529058",
        "EndpointID": "e6235dff3c6d33bf3b151e8cdbab5082c69e25afb9cccbf38912e6c328443b0b",
        "Gateway": "172.17.17.1",
        "IPAddress": "172.17.17.5",
        "IPPrefixLen": 24,
        "IPv6Gateway": "",
        "GlobalIPv6Address": "",
        "GlobalIPv6PrefixLen": 0,
        "MacAddress": "02:42:ac:11:11:05",
        "DriverOpts": null
    }
}
```

* 查看网桥
>每个桥接的容器会生成一个宿主机的桥接网卡与容器中eth0网卡对应
>
>brctl show
```
docker0		8000.0242c92f7551	no		veth7715aea
                                        veth9714e4d
                                        vethcf3621a
```

* 查看网卡绑定
>ip link show
```
vethcf3621a@if8
```

## 2、host
>容器不会获得独立的network namespace，而是与宿主机共用一个
>
>外部可以直接使用宿主机IP与容器端口访问容器中的服务

* 创建例举
>docker run -itd --network host nginx
```
"Networks": {
    "host": {
        "IPAMConfig": null,
        "Links": null,
        "Aliases": null,
        "NetworkID": "1e478ffa6d5e7a395c4a2e401d406baf4352f5e9d12ef3063b7bab22ba7db8b4",
        "EndpointID": "d64c20fda800ebe9527bb66996478c7e082624093ed1f8482d41d44da0cd84fc",
        "Gateway": "",
        "IPAddress": "",
        "IPPrefixLen": 0,
        "IPv6Gateway": "",
        "GlobalIPv6Address": "",
        "GlobalIPv6PrefixLen": 0,
        "MacAddress": "",
        "DriverOpts": null
    }
}
```

## 3、proxy
* 创建例举
>docker run -p 88:80 --name mynginx -d nginx

* 参数说明
```
-p <containerPort>
    将指定的容器端口映射至宿主机所有地址的一个动态端口
-p <hostPort>:<containerPort>
    将容器端口映射至宿主机的指定的端口
-p <ip>::<containerPort>
    将指定的容器端口映射至宿主机指定IP的一个动态端口
-p <ip>:<hostPort>:<containPort>
    将指定的容器端口映射至宿主机指定的IP和指定的端口
-P
    暴露容器所有的默认端口为宿主机的动态端口，与Dockerfile中EXPOSE对应
```

### a、容器访问外部
> 原理是添加iptables路由
```
宿主机IP
    192.168.1.120
容器IP
    172.17.0.0/16
```

* 对网段转发
```
iptables -t nat -A POSTROUTING -s 172.17.0.0/16 -j MASQUERADE
    MASQUERADE  all  --  172.17.0.0/16  0.0.0.0/0
```

* 单个容器转发
```
iptables -t nat POSTROUTING -s 172.17.0.2/24 -j SNAT --to 192.168.1.120
    MASQUERADE  tcp -- 172.17.0.2   172.17.0.2  tcp dpt:80
```

### b、外部访问容器
```
iptables -t nat -A PROROUTING -d 192.168.1.120 -p tcp --dport 88 -j DNAT --to 172.18.0.2:80
    DNAT    tcp --  0.0.0.0/0   0.0.0.0/0   tcp dpt:88  to:172.18.0.2:80
```

## 4、Joined containers
>联盟式容器
>
>容器创建时使用其他容器的网络，共享IP和端口等网络，但是文件系统是隔离的

```
[root@yyy4 ~]# docker run --name b1 -it --rm busybox
/ # ifconfig
eth0      Link encap:Ethernet  HWaddr 02:42:AC:11:00:02  
          inet addr:172.17.0.2  Bcast:172.17.255.255  Mask:255.255.0.0
```
>b2容器，直接使用了b1容器的网络，b1容器销毁后，b2的网卡也会丢失
```
[root@yyy4 ~]# docker run --name b2 --network container:b1 -it --rm busybox
/ # ifconfig
eth0      Link encap:Ethernet  HWaddr 02:42:AC:11:00:02  
          inet addr:172.17.0.2  Bcast:172.17.255.255  Mask:255.255.0.0
```

## 5、自定义网络
>docker network --help
```
connect     Connect a container to a network
create      Create a network
disconnect  Disconnect a container from a network
inspect     Display detailed information on one or more networks
ls          List networks
prune       Remove all unused networks
rm          Remove one or more networks
```

>docker network create -d bridge --subnet "172.26.0.0/16" --gateway "172.26.0.1" mybr0
>
>ifconfig
```
br-c68dc4008367 Link encap:以太网  硬件地址 02:42:5d:be:58:7e  
    inet 地址:172.26.0.1  广播:172.26.255.255  掩码:255.255.0.0
```


# 三、网络互通
>vim /etc/hosts
```
192.168.112.171 node1
192.168.112.172 node2
```

## 1、docker网段规划
>node1   10.1.10.1/24    192.168.112.171
>
>node2   10.1.20.1/24    192.168.112.172
>
>vim /etc/docker/daemon.json
```
{
    "bip": "10.1.10.1/24"
}
```

## 2、node1添加node2的路由
>route add -net 10.1.20.0 netmask 255.255.255.0 gw 192.168.112.172
>
>node1可以ping通node2上的docker

## 3、多节点情况
>第2步中，如果有100个节点，每个节点需要写其他99个节点的路由
>
>可以直接每个节点安装quagga，在硬件网路层面上，会相互识别学习
```
docker run -itd --name=router --privileged --net=host docker.io/georce/router
        --privileged    以特权模式运行
        --net=host      直接使用物理机的网络
```

# 四、端口映射
## 1、当创建容器时没有指定映射时
```
# 运行镜像并添加端口，可以指定多个 -p
docker run -d -p 8000:80 自定义镜像名称 /bin/bash
```

## 2、当已经有映射，需要修改时
```
1、停止容器

2、停止docker服务，目的是暂时关闭docker网卡

3、修改容器的配置文件 hostconfig.json ，又是也需要修改 config.v2.json

4、启动docker服务，docker网卡会启动

5、启动容器，配置文件会重新加载
```

## 3、docker中的端口查看
```
netstat -tunlp
```